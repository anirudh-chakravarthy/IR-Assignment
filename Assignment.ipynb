{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzMfxkBLIsHxBee0dkdgrX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudh-chakravarthy/IR-Assignment/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttni5t1c6xOG"
      },
      "source": [
        "# IR Assignment\n",
        "\n",
        "Implementation of **Fake News Detection on Social Media using Geometric Deep Learning**.\n",
        "\n",
        "Group 14:\n",
        "1. Anirudh Srinivasan Chakravarthy - 2017A7TS1195P\n",
        "2. Pradhit Ongole - 2017A3PS0188P\n",
        "3. Yashaswi Pandey - 2017B5A70971P\n",
        "4. Roshan Roy - 2017A7TS1172P\n",
        "5. Divyam Goel - 2017A7TS1196P\n",
        "\n",
        "\n",
        "## References\n",
        "1. https://github.com/KMint1819/SociaMedia/blob/ba2cca9e416461ae9916a0388cccf498b5b3ae57/hw3_gnn/Copy_of_Graph_Neural_Networks.ipynb\n",
        "2. https://github.com/YingtongDou/GCNN\n",
        "3. https://chrsmrrs.github.io/datasets/docs/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUKX2PnsGhKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b0c39e-f43e-4779-ef04-bfac5d30a72f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys83Iok4Gn8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba51797-2cea-4530-e420-22e6cccd3494"
      },
      "source": [
        "%cd gdrive/MyDrive/Academics/IR-Assignment/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Academics/IR-Assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F1N1m88CIuC"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_T4z-RG4h7"
      },
      "source": [
        "!pip install torch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uTuzLVOHTQs"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmY6x1g_DeN7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-DoNbxItpH"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "\n",
        "from sklearn.metrics import (f1_score, accuracy_score, recall_score, \n",
        "                             precision_score, roc_curve, roc_auc_score)\n",
        "import pdb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# hyper-parameters\n",
        "BATCH_SIZE = 128\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 1000\n",
        "SEED = 42\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4yzyYvvCO7K"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyyqSAoFIukK"
      },
      "source": [
        "# implementation of https://arxiv.org/abs/1902.06673\n",
        "class GeometricNet(nn.Module):\n",
        "  def __init__(self, \n",
        "               conv_in_layers,\n",
        "               conv_out_layers=64,\n",
        "               num_classes=2):\n",
        "    super(GeometricNet, self).__init__()\n",
        "\n",
        "    assert conv_out_layers % 2 == 0, 'Convolution output should have even number of layers'\n",
        "    fc_out_layers = conv_out_layers//2\n",
        "\n",
        "    self.conv1 = GATConv(conv_in_layers, conv_out_layers)\n",
        "    self.conv2 = GATConv(conv_out_layers, conv_out_layers)\n",
        "    self.fc1 = Linear(conv_out_layers, fc_out_layers)\n",
        "    self.fc2 = Linear(fc_out_layers, num_classes)\n",
        "\n",
        "    self.activation = nn.SELU(inplace=True)\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "    if data.num_node_features == 0:\n",
        "      x = torch.ones(data.num_nodes, 1, device=torch.cuda.current_device())\n",
        "\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = self.activation(x)\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = self.activation(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "# evaluation metrics\n",
        "def test(model, loader):\n",
        "  acc, f1, precision, recall = 0., 0., 0., 0.\n",
        "  model.eval()\n",
        "\n",
        "  for i, data in enumerate(loader):\n",
        "    y = data.y.cpu().numpy()\n",
        "    data = data.to(torch.cuda.current_device())\n",
        "    pred = model(data)\n",
        "    y_pred = F.softmax(pred, dim=-1).argmax(dim=1).cpu().numpy()\n",
        "    acc += accuracy_score(y, y_pred)\n",
        "    f1 += f1_score(y, y_pred, average='macro')\n",
        "    precision += precision_score(y, y_pred, zero_division=0)\n",
        "    recall += recall_score(y, y_pred, zero_division=0)\n",
        "\n",
        "  acc /= len(test_loader)\n",
        "  f1 /= len(test_loader)\n",
        "  precision /= len(test_loader)\n",
        "  recall /= len(test_loader)\n",
        "  return acc, f1, precision, recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4qyTiDCEJN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqoph5yQKYGa"
      },
      "source": [
        "# 3 datasets tested: AIDS, PROTEINS, SYNTHETIC\n",
        "# dataset = TUDataset(root='data/', name='AIDS', use_node_attr=True)\n",
        "# dataset = TUDataset(root='data/', name='PROTEINS', use_node_attr=True)\n",
        "dataset = TUDataset(root='data/', name='SYNTHETIC', use_node_attr=True)\n",
        "\n",
        "# random 80-20 split for training and test loader\n",
        "num_training = int(len(dataset) * 0.8)\n",
        "num_test = len(dataset) - num_training\n",
        "training_set, test_set = random_split(dataset, [num_training, num_test], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "train_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZDXbJfJQbAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01094e2-1972-4754-829e-8f8e6e249749"
      },
      "source": [
        "# instantiate model, optimizer, and hinge-loss\n",
        "model = GeometricNet(max(dataset.num_node_features, 1), \n",
        "                     num_classes=dataset.num_classes).to(torch.cuda.current_device())\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.MultiMarginLoss() # nn.CrossEntropyLoss()\n",
        "\n",
        "# training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model.train()\n",
        "  for i, data in enumerate(train_loader):\n",
        "    data = data.to(torch.cuda.current_device())\n",
        "    pred = model(data)\n",
        "    loss = loss_fn(pred, data.y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # print evaluation stats every 10 epochs\n",
        "  if epoch % 10 == 0:\n",
        "    acc, f1, precision, recall = test(model, test_loader)\n",
        "    print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}, F1: {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(\n",
        "        epoch, loss, acc, f1, precision, recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Loss: 0.5006. Test accuracy: 0.4333, F1: 0.3023, Precision: 0.0000, Recall: 0.0000\n",
            "Epoch 10. Loss: 0.4710. Test accuracy: 0.4333, F1: 0.3023, Precision: 0.0000, Recall: 0.0000\n",
            "Epoch 20. Loss: 0.4774. Test accuracy: 0.4333, F1: 0.3023, Precision: 0.0000, Recall: 0.0000\n",
            "Epoch 30. Loss: 0.4374. Test accuracy: 0.5333, F1: 0.5200, Precision: 0.6875, Recall: 0.3235\n",
            "Epoch 40. Loss: 0.3981. Test accuracy: 0.6833, F1: 0.6760, Precision: 0.7143, Recall: 0.7353\n",
            "Epoch 50. Loss: 0.3473. Test accuracy: 0.7333, F1: 0.7222, Precision: 0.7368, Recall: 0.8235\n",
            "Epoch 60. Loss: 0.2736. Test accuracy: 0.7833, F1: 0.7818, Precision: 0.8387, Recall: 0.7647\n",
            "Epoch 70. Loss: 0.2929. Test accuracy: 0.7833, F1: 0.7644, Precision: 0.7442, Recall: 0.9412\n",
            "Epoch 80. Loss: 0.1968. Test accuracy: 0.7500, F1: 0.7499, Precision: 0.8519, Recall: 0.6765\n",
            "Epoch 90. Loss: 0.2165. Test accuracy: 0.8167, F1: 0.8141, Precision: 0.8485, Recall: 0.8235\n",
            "Epoch 100. Loss: 0.1757. Test accuracy: 0.8333, F1: 0.8316, Precision: 0.8750, Recall: 0.8235\n",
            "Epoch 110. Loss: 0.2152. Test accuracy: 0.8167, F1: 0.8141, Precision: 0.8485, Recall: 0.8235\n",
            "Epoch 120. Loss: 0.2150. Test accuracy: 0.8333, F1: 0.8316, Precision: 0.8750, Recall: 0.8235\n",
            "Epoch 130. Loss: 0.1416. Test accuracy: 0.8333, F1: 0.8316, Precision: 0.8750, Recall: 0.8235\n",
            "Epoch 140. Loss: 0.1780. Test accuracy: 0.8500, F1: 0.8479, Precision: 0.8788, Recall: 0.8529\n",
            "Epoch 150. Loss: 0.1965. Test accuracy: 0.8667, F1: 0.8665, Precision: 0.9643, Recall: 0.7941\n",
            "Epoch 160. Loss: 0.1852. Test accuracy: 0.8667, F1: 0.8611, Precision: 0.8421, Recall: 0.9412\n",
            "Epoch 170. Loss: 0.1823. Test accuracy: 0.8833, F1: 0.8830, Precision: 0.9655, Recall: 0.8235\n",
            "Epoch 180. Loss: 0.1796. Test accuracy: 0.9167, F1: 0.9147, Precision: 0.9143, Recall: 0.9412\n",
            "Epoch 190. Loss: 0.1262. Test accuracy: 0.9000, F1: 0.8996, Precision: 0.9667, Recall: 0.8529\n",
            "Epoch 200. Loss: 0.1559. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 210. Loss: 0.2014. Test accuracy: 0.8833, F1: 0.8830, Precision: 0.9655, Recall: 0.8235\n",
            "Epoch 220. Loss: 0.1755. Test accuracy: 0.9167, F1: 0.9161, Precision: 0.9677, Recall: 0.8824\n",
            "Epoch 230. Loss: 0.1506. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 240. Loss: 0.1445. Test accuracy: 0.9500, F1: 0.9483, Precision: 0.9189, Recall: 1.0000\n",
            "Epoch 250. Loss: 0.1087. Test accuracy: 0.9667, F1: 0.9657, Precision: 0.9444, Recall: 1.0000\n",
            "Epoch 260. Loss: 0.1798. Test accuracy: 0.9500, F1: 0.9483, Precision: 0.9189, Recall: 1.0000\n",
            "Epoch 270. Loss: 0.1569. Test accuracy: 0.9500, F1: 0.9483, Precision: 0.9189, Recall: 1.0000\n",
            "Epoch 280. Loss: 0.1067. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 290. Loss: 0.1203. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 300. Loss: 0.0943. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 310. Loss: 0.1091. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 320. Loss: 0.1124. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 330. Loss: 0.0865. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 340. Loss: 0.0954. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 350. Loss: 0.0669. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 360. Loss: 0.0853. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 370. Loss: 0.0686. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 380. Loss: 0.0951. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 390. Loss: 0.0569. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 400. Loss: 0.0704. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 410. Loss: 0.0732. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 420. Loss: 0.1101. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 430. Loss: 0.0656. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 440. Loss: 0.0709. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 450. Loss: 0.0569. Test accuracy: 0.9500, F1: 0.9483, Precision: 0.9189, Recall: 1.0000\n",
            "Epoch 460. Loss: 0.1436. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 470. Loss: 0.0864. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 480. Loss: 0.0704. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 490. Loss: 0.0689. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 500. Loss: 0.0590. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 510. Loss: 0.0769. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 520. Loss: 0.0835. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 530. Loss: 0.0893. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 540. Loss: 0.0437. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 550. Loss: 0.0473. Test accuracy: 0.9833, F1: 0.9829, Precision: 0.9714, Recall: 1.0000\n",
            "Epoch 560. Loss: 0.0899. Test accuracy: 0.9667, F1: 0.9657, Precision: 0.9444, Recall: 1.0000\n",
            "Epoch 570. Loss: 0.1346. Test accuracy: 0.9667, F1: 0.9657, Precision: 0.9444, Recall: 1.0000\n",
            "Epoch 580. Loss: 0.0565. Test accuracy: 0.9667, F1: 0.9657, Precision: 0.9444, Recall: 1.0000\n",
            "Epoch 590. Loss: 0.0509. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 600. Loss: 0.0593. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 610. Loss: 0.0468. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 620. Loss: 0.0726. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 630. Loss: 0.0864. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 640. Loss: 0.0631. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 650. Loss: 0.0788. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 660. Loss: 0.0553. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 670. Loss: 0.0670. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 680. Loss: 0.0779. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 690. Loss: 0.0600. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 700. Loss: 0.0664. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 710. Loss: 0.0498. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 720. Loss: 0.0581. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 730. Loss: 0.0445. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 740. Loss: 0.0576. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 750. Loss: 0.0585. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 760. Loss: 0.0643. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 770. Loss: 0.0934. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 780. Loss: 0.0542. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 790. Loss: 0.0551. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 800. Loss: 0.0442. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 810. Loss: 0.0713. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 820. Loss: 0.0426. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 830. Loss: 0.0433. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 840. Loss: 0.0295. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 850. Loss: 0.0607. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 860. Loss: 0.0636. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 870. Loss: 0.0354. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 880. Loss: 0.0369. Test accuracy: 0.9500, F1: 0.9488, Precision: 0.9429, Recall: 0.9706\n",
            "Epoch 890. Loss: 0.0390. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 900. Loss: 0.0369. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 910. Loss: 0.0496. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 920. Loss: 0.0454. Test accuracy: 0.9500, F1: 0.9488, Precision: 0.9429, Recall: 0.9706\n",
            "Epoch 930. Loss: 0.0341. Test accuracy: 0.9667, F1: 0.9661, Precision: 0.9706, Recall: 0.9706\n",
            "Epoch 940. Loss: 0.0595. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n",
            "Epoch 950. Loss: 0.0197. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 960. Loss: 0.0348. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 970. Loss: 0.0507. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 980. Loss: 0.0658. Test accuracy: 0.9333, F1: 0.9327, Precision: 0.9688, Recall: 0.9118\n",
            "Epoch 990. Loss: 0.0509. Test accuracy: 0.9500, F1: 0.9493, Precision: 0.9697, Recall: 0.9412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwd5cbh4CA7S"
      },
      "source": [
        "## ROC curve and AUC "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7jCrVeiyYo0"
      },
      "source": [
        "gt, probs = [], []\n",
        "model.eval()\n",
        "for i, data in enumerate(test_loader):\n",
        "    y = data.y.cpu().numpy()\n",
        "    gt.extend(y)\n",
        "    data = data.to(torch.cuda.current_device())\n",
        "    pred = model(data)\n",
        "    prob = F.softmax(pred, dim=-1)[:, 1].detach().cpu().numpy() # class label\n",
        "    probs.extend(prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxSZVo-9C9ZQ",
        "outputId": "83a95816-de3f-4236-8fea-d626a0ba8b54"
      },
      "source": [
        "auc = roc_auc_score(np.array(gt), np.array(probs))\n",
        "print(auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9909502262443438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "70vz74aFERNa",
        "outputId": "9cfebc5d-3a0f-4424-e71c-509dfae0bab8"
      },
      "source": [
        "fpr, tpr, _ = roc_curve(np.array(gt), np.array(probs))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPLEnlSREtAo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}